# ap_words (応用)情報技術者試験シラバス用・用語抽出スクリプト

## 概要

応用情報技術者試験のシラバス(用語例の塊) の用語例を抽出し、解説をLLMに作ってもらうプロンプトテキストを作ります。単純に用語のみを出力する事もできます。
基本情報のシラバスを見た記憶では同じ作りでしたが、他のIPA試験のシラバスにも対応してると推測します(未確認)。

-----

## 使い方

1.  **シラバスファイルの準備**: 公式シラバスPDFのテキスト内容を全選択してコピペし、プレーンテキストファイルとして保存します。ここでは例として `syllabus.txt` というファイルにコピペしたとします。
<br> 
2.  **スクリプトの実行**: ターミナルで、ファイル名を指定してスクリプトを実行します。
```zsh
python3 ap_words.py syllabus.txt
```
出力は標準出力に対して行われるので、次のようにして適宜保存してください。
```zsh
python3 ap_words.py syllabus.txt > ap_words.txt
```
なお、デフォルトではシラバス中の他のテキストも出力して、シラバス中の文脈の中にAIお願いプロンプト文が挿入されていきますが、用語のみの羅列や、お願いプロンプト文のみの羅列も可能です (後述) 。
<br> 
3. 出力されたテキストを、テキストエディタや Word や Google Document 等で開いてください。以下のような _ask で始まる行段落がありますので、それをコピペして LLM (ChatGPT や Gemini) に貼り付けてください。
```text
_ask
応用情報処理試験の出題範囲「AI（Artificial Intelligence：人工知能）に関する技術」における「自然言語処理、音声・画像・動画の認識・合成・生成などへの応用」について、
以下の用語に関する解説(基本的には400文字以内で、内容が複雑な場合は最大600文字、
意味が単純なら文字数に合わせず簡潔にまとめてもいい)を、表形式でまとめてください。
なお、文体は簡潔にするために、「だ・である」系や体言止めでお願いします。
畳み込みニューラルネットワーク（CNN）
リカレントニューラルネットワーク（RNN）
LSTM（Long Short Term Memory）
生成モデル
オートエンコーダ
敵対的生成ネットワーク（GAN）
深層強化学習
基盤モデル
拡散モデル
言語モデル
大規模言語モデル（LLM）
Transformer
自己注意（Self-Attention）機構
自己教師あり学習
アラインメント
人間のフィードバックによる強化学習（RLHF）
ゼロショット学習
フューショット学習
インストラクションチューニング
プロンプトエンジニアリング
モデル圧縮（蒸留、量子化、プルーニング）文脈自由文法
中間言語
目的プログラム
形式言語
オートマトン手続型言語
関数型言語
論理型言語
オブジェクト指向言語
```

以下は Gemini の回答例です。
> 承知しました。人工知能の分野から、ご指定の用語について解説を表形式でまとめる。

---

### ニューラルネットワーク

| 用語 | 解説 |
| :--- | :--- |
| **畳み込みニューラルネットワーク（CNN）** | 画像認識に特化したニューラルネットワーク。畳み込み層とプーリング層を交互に配置することで、画像の特徴を効率的に抽出し、パターン認識を行う。コンピュータビジョン分野で広く使われる。 |
| **リカレントニューラルネットワーク（RNN）** | 時系列データや連続的なデータを扱うのに適したニューラルネットワーク。過去の情報を保持する「再帰的な」構造を持ち、言語や音声などの予測に利用される。 |
| **LSTM（Long Short Term Memory）** | RNNの一種で、長期的な依存関係を学習する能力に優れる。従来のRNNが抱える勾配消失問題を解決し、音声認識や機械翻訳の精度を大幅に向上させた。 |

---

### 生成モデルと学習手法

| 用語 | 解説 |
| :--- | :--- |
| **生成モデル** | データの分布を学習し、元のデータに似た新たなデータを生成するモデル。画像生成や音楽生成などに使われる。 |
| **オートエンコーダ** | 入力データを圧縮して潜在空間に変換する「エンコーダ」と、潜在空間から元のデータを復元する「デコーダ」で構成されるニューラルネットワーク。データの次元削減や異常検知に用いられる。 |
| **敵対的生成ネットワーク（GAN）** | 互いに競い合う2つのニューラルネットワーク（生成器と識別器）で構成される生成モデル。よりリアルな画像を生成する生成器と、その真偽を見破ろうとする識別器が互いを高め合う。 |
| **深層強化学習** | 強化学習と深層学習を組み合わせた学習手法。エージェントが、環境からの報酬を最大化するように行動を学習する。ロボット制御やゲームAIに利用される。 |
| **自己教師あり学習** | ラベル付けされていない大量のデータから、データ自体が持つ構造やパターンを学習する手法。データの一部を隠して予測させたり、元のデータを変換して学習させたりする。 |
| **アラインメント** | AIモデルの振る舞いを、人間の価値観や意図と一致させるプロセス。モデルの出力が不適切でないか、倫理的であるかなどを評価する。 |
| **人間のフィードバックによる強化学習（RLHF）** | AIの出力に対する人間の評価を報酬として、強化学習を行う手法。AIの応答をより人間らしく、有益にするために用いられる。 |

---

### 大規模言語モデルとTransformer

| 用語 | 解説 |
| :--- | :--- |
| **基盤モデル** | 大規模なデータで学習された、多様なタスクに応用可能な汎用的なモデル。テキストや画像など、複数のモダリティ（形式）を扱える場合もある。 |
| **拡散モデル** | ノイズから画像を生成する生成モデルの一種。ノイズを加えるプロセスを逆再生することで、徐々にクリアな画像を生成する。高精細な画像生成に優れる。 |
| **言語モデル** | 特定の単語や文が次に現れる確率を予測するモデル。自然言語処理の基盤技術であり、テキスト生成や機械翻訳に応用される。 |
| **大規模言語モデル（LLM）** | 膨大なテキストデータで学習された、非常に大規模な言語モデル。対話、要約、プログラミングコードの生成など、多様なタスクに対応できる。 |
| **Transformer** | 自然言語処理の分野に革命をもたらしたニューラルネットワークのモデル。再帰的な構造を持たず、入力された単語間の関係性を並列に学習する。 |
| **自己注意（Self-Attention）機構** | Transformerの核となる技術。入力された文中の各単語が、文中の他のどの単語と関連性が強いかを評価し、重要度を動的に判断する。 |
| **ゼロショット学習** | 未知のタスクや、学習時に見たことのないデータに対しても、追加の学習なしで対応する能力。 |
| **フューショット学習** | わずかな例（数ショット）を提示するだけで、未知のタスクを実行する能力。モデルが指示を理解し、その場で学習する。 |
| **インストラクションチューニング** | モデルにタスクの指示（インストラクション）を与えて学習させる手法。これにより、モデルはさまざまな指示を理解し、それに従う能力を身につける。 |
| **プロンプトエンジニアリング** | LLMの能力を最大限に引き出すために、モデルへの入力（プロンプト）を最適化する技術。 |
| **モデル圧縮** | 大規模モデルを、推論速度やメモリ効率を向上させるために小型化する技術。**蒸留**（より大きなモデルの知識を小さなモデルに転移）、**量子化**（モデルの重みを低精度化）、**プルーニング**（不要な重みを削除）などの手法がある。 |

---

### プログラミング言語と形式言語

| 用語 | 解説 |
| :--- | :--- |
| **文脈自由文法** | 形式文法の一つ。プログラミング言語の構文解析に用いられ、文脈に依存しない形で文字列の構造を記述する。 |
| **中間言語** | ソースプログラムを直接機械語に変換するのではなく、一度中間的な形式に変換した言語。コンパイラの開発効率を向上させる。 |
| **目的プログラム** | コンパイラがソースプログラムをコンパイルした結果生成される、機械語などで書かれた実行可能なプログラム。 |
| **形式言語** | 厳密な数学的規則に基づいて定義された言語。コンピュータ科学において、プログラミング言語の構文やオートマトン理論の基礎となる。 |
| **オートマトン** | 形式言語を認識（受理）する仮想的な機械のモデル。有限オートマトンなどが含まれ、コンパイラの字句解析などに用いられる。 |
| **手続型言語** | 処理の手順（手続き）を記述することでプログラムを作成する言語。命令を順次実行する。C言語やPascalが代表例。 |
| **関数型言語** | 関数の組み合わせでプログラムを記述する言語。副作用を排し、数学的な関数の概念に基づいて計算を行う。LispやHaskellが代表例。 |
| **論理型言語** | 論理学に基づいてプログラムを記述する言語。事実とルールの記述を通じて、推論によって問題を解決する。Prologが代表例。 |
| **オブジェクト指向言語** | データと、そのデータを操作する手続きを一体化した「オブジェクト」を基本単位としてプログラムを記述する言語。JavaやC++が代表例。 |

4. 補足として、Mac/Linux環境では下記のようにしてスクリプトに実行権限を与えると
```zsh
chmod +x ap_words.py
```
以下のように python3 を省いて実行できます。
```zsh
./ap_words.py syllabus.txt
```
## コマンド詳細
```text
ap_words.py <command> <filename>
<filename>: IPAシラバスを全選択コピペしたテキストファイル
<command>:
normal(default) : 通常の処理。「用語解説お願い」以外のテキストも出力する。
ask : 用語解説お願いテキストのみを出力する。
dict : 用語のみを出力する。
```
使用例
```zsh
./ap_words.py ask syllabus.txt > ap_ask.txt
./ap_words.py dict syllabus.txt > apwords.txt
./ap_words.py syllabus.txt > ap_guide.txt
```

## 機能詳細 📝
  - **コマンド(動作モード)**: 用途に合わせて3つの出力モードを選択できます。
      - **`normal`**: デフォルト動作。シラバスのテキストと、AI用プロンプトの両方を出力します。文量は冗長となりますが、シラバス中のどのような文脈でそれらの用語が出てきたのかわかりやすいモードです。
      - **`ask`**: AI用プロンプトテキストのみを出力します。どのような文脈でそれらの用語が出てきたのか、少々わかりにくくなりますが、調べたい用語が明確であるならばコピー＆ペーストしやすいといえます。
      - **`dict`**: 抽出された用語のみをひたすら羅列します。
  * **見出しの認識**: `(2) 見出し1` や `① 見出し2` といった見出し部を認識し、AIに質問する際のキーワードとしています。このほかの「中分類」だとかは曖昧すぎるので AI に質問する際のキーワードとして必要ないと仮定しています。
  * **用語例の抽出**: 用語の区切り文字として「，」が指定されていますが、念の為「、」も区切り文字として指定されています。
  * **括弧内のカンマは無視**: `（...、...）` のように括弧で囲まれた中のカンマは、用語区切りの対象とはしません。

-----


## トラブルシューティング

  - **`FileNotFoundError`**: シラバスのテキストファイルへのパスが正しいことを確認してください。
  - **`BrokenPipeError`**: このエラーは、出力を`less`のようなコマンドにパイプすると、ap_words 側が出力を終える前に`less`が終了してしまった時などに出力できないというようなメカニズムで発生するようです。
  - そもそも有料プランか何かで丸ごと LLM に読み込ませて適当にお願いすれば全部やってくれるんじゃないかという気もしますが、Python 練習作品第一弾として作ったものにつきあしからず。

## 作者

Junichiro Higuchi

## ライセンス

このプロジェクトは[MITライセンス](https://opensource.org/licenses/MIT)の下で公開されています。
